{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read & Import","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport cv2\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport json\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import class_weight\nimport shutil\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:28:51.313987Z","iopub.execute_input":"2025-04-15T22:28:51.314570Z","iopub.status.idle":"2025-04-15T22:28:56.116746Z","execution_failed":"2025-04-15T23:47:11.962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = \"/kaggle/input/merged-dataset\"\n\ncategories = [ 'normal', 'covid19', 'pneumonia']\nimages = []\nlabels = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:28:59.861828Z","iopub.execute_input":"2025-04-15T22:28:59.862162Z","iopub.status.idle":"2025-04-15T22:28:59.866821Z","shell.execute_reply.started":"2025-04-15T22:28:59.862135Z","shell.execute_reply":"2025-04-15T22:28:59.865805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_images_from_folder(folder, label):\n    for filename in os.listdir(folder):\n        if filename.endswith('.jpg') or filename.endswith('.png') :\n            img_path = os.path.join(folder, filename)\n            try:\n                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n                img = cv2.resize(img, (224, 224))\n                images.append(img)\n                labels.append(label)\n            except Exception as e:\n                print(f\"Error loading image {img_path}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:06.369124Z","iopub.execute_input":"2025-04-15T22:29:06.369426Z","iopub.status.idle":"2025-04-15T22:29:06.375603Z","shell.execute_reply.started":"2025-04-15T22:29:06.369405Z","shell.execute_reply":"2025-04-15T22:29:06.374536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = os.path.join(base_path, 'train')\nfor category in categories:\n    category_path = os.path.join(train_path, category)\n    print(f\"Loading training data from {category_path}...\")\n    load_images_from_folder(category_path, category)\n\ntest_path = os.path.join(base_path, 'test')\ntest_images = []\ntest_labels = []\nfor category in categories:\n    category_path = os.path.join(test_path, category)\n    print(f\"Loading test data from {category_path}...\")\n    load_images_from_folder(category_path, category)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:06.713901Z","iopub.execute_input":"2025-04-15T22:29:06.714248Z","iopub.status.idle":"2025-04-15T22:29:10.235383Z","shell.execute_reply.started":"2025-04-15T22:29:06.714218Z","shell.execute_reply":"2025-04-15T22:29:10.234104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = np.array(images)\nlabels = np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:10.237359Z","iopub.execute_input":"2025-04-15T22:29:10.237871Z","iopub.status.idle":"2025-04-15T22:29:10.277410Z","shell.execute_reply.started":"2025-04-15T22:29:10.237838Z","shell.execute_reply":"2025-04-15T22:29:10.276437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for Visualization\nstart = 1\nnum_img = 4\nmain_labels = ['covid19', 'normal', 'pneumonia']\nlabel_mapping = {'covid19': 0, 'normal': 1, 'pneumonia': 2}\n\nlabels = np.array([label_mapping[lbl] for lbl in labels])\nprint(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:10.278544Z","iopub.execute_input":"2025-04-15T22:29:10.278913Z","iopub.status.idle":"2025-04-15T22:29:10.287243Z","shell.execute_reply.started":"2025-04-15T22:29:10.278881Z","shell.execute_reply":"2025-04-15T22:29:10.286432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_copy = np.copy(images)\nlabels_copy = np.copy(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:10.289341Z","iopub.execute_input":"2025-04-15T22:29:10.289683Z","iopub.status.idle":"2025-04-15T22:29:10.334328Z","shell.execute_reply.started":"2025-04-15T22:29:10.289654Z","shell.execute_reply":"2025-04-15T22:29:10.333332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Visualization(images, labels, start, num_img, title_prefix=\"Original\"):\n    fig, ax = plt.subplots(1, num_img, sharey=True, figsize=(num_img*10, 10))\n    for q in range(num_img):\n        idx = start + q\n        if idx >= len(images):\n            break\n        img = images[idx]\n        img = img[..., 0] if len(img.shape) == 3 else img\n        ax[q].imshow(img, cmap=plt.cm.bone)\n        ax[q].set_title(f\"{title_prefix} - {main_labels[labels[idx]]}\", fontsize=12)\n        ax[q].axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:10.335394Z","iopub.execute_input":"2025-04-15T22:29:10.335706Z","iopub.status.idle":"2025-04-15T22:29:10.341921Z","shell.execute_reply.started":"2025-04-15T22:29:10.335682Z","shell.execute_reply":"2025-04-15T22:29:10.341038Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"print('Original images: ')\nVisualization(images_copy, labels_copy, start, num_img, \"Original\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:10.342870Z","iopub.execute_input":"2025-04-15T22:29:10.343128Z","iopub.status.idle":"2025-04-15T22:29:11.389218Z","shell.execute_reply.started":"2025-04-15T22:29:10.343104Z","shell.execute_reply":"2025-04-15T22:29:11.388195Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Normalization","metadata":{}},{"cell_type":"code","source":"images_copy = images_copy.astype('float32') / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:12.518749Z","iopub.execute_input":"2025-04-15T22:29:12.519112Z","iopub.status.idle":"2025-04-15T22:29:12.661691Z","shell.execute_reply.started":"2025-04-15T22:29:12.519084Z","shell.execute_reply":"2025-04-15T22:29:12.660943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Original Images:')\nVisualization(images, labels, start, num_img, \"Original\")\n\nprint('Normalized Images: ')\nVisualization(images_copy, labels_copy, start, num_img, \"Normalized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:12.748711Z","iopub.execute_input":"2025-04-15T22:29:12.749109Z","iopub.status.idle":"2025-04-15T22:29:14.411063Z","shell.execute_reply.started":"2025-04-15T22:29:12.749083Z","shell.execute_reply":"2025-04-15T22:29:14.410090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Standardization","metadata":{}},{"cell_type":"code","source":"mean = np.mean(images_copy, axis=(0, 1, 2))\nstd = np.std(images_copy, axis=(0, 1, 2))\nimages_copy = (images_copy - mean) / std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:14.412516Z","iopub.execute_input":"2025-04-15T22:29:14.412866Z","iopub.status.idle":"2025-04-15T22:29:14.683232Z","shell.execute_reply.started":"2025-04-15T22:29:14.412843Z","shell.execute_reply":"2025-04-15T22:29:14.681875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Original Images:')\nVisualization(images, labels, start, num_img, \"Original\")\n\nprint('Standardized Images: ')\nVisualization(images_copy, labels_copy, start, num_img, \"Standardized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:14.684154Z","iopub.execute_input":"2025-04-15T22:29:14.684423Z","iopub.status.idle":"2025-04-15T22:29:16.574491Z","shell.execute_reply.started":"2025-04-15T22:29:14.684401Z","shell.execute_reply":"2025-04-15T22:29:16.573508Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Gaussian Smothing","metadata":{}},{"cell_type":"markdown","source":"**Less smoothing:**\n\n- Less kernel_size\n- less sigma","metadata":{}},{"cell_type":"code","source":"kernel_size = (3, 3)\nsigma = 0.2\n\nimages_copy = [None] * len(images)\n\nfor i in range(len(images)):\n    blurred = cv2.GaussianBlur(images[i], kernel_size, sigma)\n    blurred_expanded = np.expand_dims(blurred, axis=-1)\n    images_copy[i] = blurred_expanded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:16.576242Z","iopub.execute_input":"2025-04-15T22:29:16.576560Z","iopub.status.idle":"2025-04-15T22:29:16.672913Z","shell.execute_reply.started":"2025-04-15T22:29:16.576536Z","shell.execute_reply":"2025-04-15T22:29:16.671934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Original Images:')\nVisualization(images, labels, start, num_img, \"Original\")\n\nprint('Smothed Images: ')\nVisualization(images_copy, labels_copy, start, num_img, \"Smoothed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:16.673771Z","iopub.execute_input":"2025-04-15T22:29:16.674097Z","iopub.status.idle":"2025-04-15T22:29:18.311896Z","shell.execute_reply.started":"2025-04-15T22:29:16.674070Z","shell.execute_reply":"2025-04-15T22:29:18.310834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Contrast Enhancement","metadata":{}},{"cell_type":"markdown","source":"**Preform Histogram Equalization to improves contrast**","metadata":{}},{"cell_type":"markdown","source":"***createCLAHE parameters:***\n\n**clipLimit**: \n\n3.0 or 4.0 => more contrast\n\n1.0 => less contrast if noise is amplified\n\n**tileGridSize:**\n\n(16, 16) => more global enhancement\n\n(4, 4) => more local enhancement","metadata":{}},{"cell_type":"code","source":"clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))\nclahe_imgs = []\nfor img in images_copy:\n    img_scaled = (img - img.min()) / (img.max() - img.min())\n    img_uint8 = (img_scaled * 255).astype(np.uint8)\n    img_clahe = clahe.apply(img_uint8) / 255.0\n    clahe_imgs.append(img_clahe)\nimages_copy = np.array(clahe_imgs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:18.313679Z","iopub.execute_input":"2025-04-15T22:29:18.314014Z","iopub.status.idle":"2025-04-15T22:29:19.654403Z","shell.execute_reply.started":"2025-04-15T22:29:18.313989Z","shell.execute_reply":"2025-04-15T22:29:19.653423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Original Images:')\nVisualization(images, labels, start, num_img, \"Original\")\n\nprint('Contrast Enhanced Images: ')\nVisualization(images_copy, labels_copy, start, num_img, \"CLAHE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:19.655651Z","iopub.execute_input":"2025-04-15T22:29:19.656033Z","iopub.status.idle":"2025-04-15T22:29:21.399763Z","shell.execute_reply.started":"2025-04-15T22:29:19.656000Z","shell.execute_reply":"2025-04-15T22:29:21.398549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gamma = 1.2\ngamma_imgs = []\nfor img in images_copy:\n    img_scaled = (img - img.min()) / (img.max() - img.min())\n    img_gamma = np.power(img_scaled, gamma)\n    gamma_imgs.append(img_gamma)\n\nimages_copy = np.array(gamma_imgs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:21.401133Z","iopub.execute_input":"2025-04-15T22:29:21.401407Z","iopub.status.idle":"2025-04-15T22:29:23.736098Z","shell.execute_reply.started":"2025-04-15T22:29:21.401385Z","shell.execute_reply":"2025-04-15T22:29:23.735163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Original Images:')\nVisualization(images, labels, start, num_img, \"Original\")\n\nprint('Gamma Corrected Images: ')\nVisualization(images_copy, labels_copy, start, num_img, \"Gamma\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:23.737314Z","iopub.execute_input":"2025-04-15T22:29:23.737610Z","iopub.status.idle":"2025-04-15T22:29:25.437365Z","shell.execute_reply.started":"2025-04-15T22:29:23.737565Z","shell.execute_reply":"2025-04-15T22:29:25.436228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Sharpening","metadata":{}},{"cell_type":"code","source":"kernel = np.array([[0, -1, 0],\n                   [-1, 5, -1],\n                   [0, -1, 0]])\nimages_copy2 = cv2.filter2D(images_copy, -1, kernel)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:25.438385Z","iopub.execute_input":"2025-04-15T22:29:25.438692Z","iopub.status.idle":"2025-04-15T22:29:25.729078Z","shell.execute_reply.started":"2025-04-15T22:29:25.438668Z","shell.execute_reply":"2025-04-15T22:29:25.728113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('smoothed Images:')\nVisualization(images, labels, start, num_img, \"Original\")\n\nprint('Sharpened Images: ')\nVisualization(images_copy2, labels_copy, start, num_img, \"Sharped\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:29:25.730711Z","iopub.execute_input":"2025-04-15T22:29:25.731076Z","iopub.status.idle":"2025-04-15T22:29:27.408990Z","shell.execute_reply.started":"2025-04-15T22:29:25.731045Z","shell.execute_reply":"2025-04-15T22:29:27.407878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Handling Class Imbalance","metadata":{}},{"cell_type":"code","source":"unique_labels, counts = np.unique(labels, return_counts=True)\nprint('unique_labels: ', unique_labels)\nprint('counts: ', counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:31:30.038380Z","iopub.execute_input":"2025-04-15T22:31:30.038735Z","iopub.status.idle":"2025-04-15T22:31:30.044987Z","shell.execute_reply.started":"2025-04-15T22:31:30.038708Z","shell.execute_reply":"2025-04-15T22:31:30.044138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_count = 504\nn_samples, h, w = images_copy.shape[:3]\n\noversampled_images = []\noversampled_labels = []\n\n# Oversample each class\nfor class_idx in range(len(main_labels)):\n    # Get indices of images in this class\n    class_indices = np.where(labels_copy == class_idx)[0]\n    class_images = images_copy[class_indices]\n    class_labels = labels_copy[class_indices]\n    \n    # Calculate how many additional samples are needed\n    current_count = len(class_indices)\n    samples_needed = target_count - current_count\n    \n    if samples_needed > 0:\n        # Randomly duplicate images to reach the target count\n        duplicate_indices = np.random.choice(current_count, samples_needed, replace=True)\n        duplicated_images = class_images[duplicate_indices]\n        duplicated_labels = class_labels[duplicate_indices]\n        \n        # Add original images\n        oversampled_images.append(class_images)\n        oversampled_labels.append(class_labels)\n        \n        # Add duplicated images\n        oversampled_images.append(duplicated_images)\n        oversampled_labels.append(duplicated_labels)\n    else:\n        # No oversampling needed, just add original images\n        oversampled_images.append(class_images)\n        oversampled_labels.append(class_labels)\n\n# Concatenate all images and labels\noversampled_images = np.concatenate(oversampled_images, axis=0)\noversampled_labels = np.concatenate(oversampled_labels, axis=0)\n\n# Augment oversampled images to add diversity\ndatagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\naugmented_images, augmented_labels = [], []\nfor i in range(len(oversampled_images)):\n    img = oversampled_images[i].reshape(1, h, w, 1)\n    label = oversampled_labels[i]\n    for batch in datagen.flow(img, batch_size=1, seed=42):\n        augmented_images.append(batch[0, ..., 0])\n        augmented_labels.append(label)\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:31:39.343394Z","iopub.execute_input":"2025-04-15T22:31:39.343834Z","iopub.status.idle":"2025-04-15T22:31:45.371348Z","shell.execute_reply.started":"2025-04-15T22:31:39.343806Z","shell.execute_reply":"2025-04-15T22:31:45.370563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Number of images in total is \", len(augmented_images))\nCOVID19_count = 0\nNORMAL_count = 0\nPNEUMONIA_count = 0\nfor label in augmented_labels:\n    if label == 0:\n        COVID19_count+=1\n    elif label == 1:\n        NORMAL_count +=1\n    elif label == 2:\n        PNEUMONIA_count+=1\nprint(f\"Number of images in COVID19 class is {COVID19_count}\")\nprint(f\"Number of images in NORMAL class is {NORMAL_count}\")\nprint(f\"Number of images in PNEUMONIA class is {PNEUMONIA_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:31:49.276733Z","iopub.execute_input":"2025-04-15T22:31:49.277100Z","iopub.status.idle":"2025-04-15T22:31:49.283968Z","shell.execute_reply.started":"2025-04-15T22:31:49.277070Z","shell.execute_reply":"2025-04-15T22:31:49.282897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_copy = np.array(augmented_images)\nlabels_copy = np.array(augmented_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:31:52.440968Z","iopub.execute_input":"2025-04-15T22:31:52.441295Z","iopub.status.idle":"2025-04-15T22:31:52.541462Z","shell.execute_reply.started":"2025-04-15T22:31:52.441269Z","shell.execute_reply":"2025-04-15T22:31:52.540606Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save for next stage","metadata":{}},{"cell_type":"code","source":"base_dir = \"/kaggle/working/dataset\"\ntrain_dir = os.path.join(base_dir, \"train\")\ntest_dir = os.path.join(base_dir, \"test\")\nclass_names = ['covid19', 'normal', 'pneumonia']\nzip_file = \"dataset.zip\"\n\nfor split_dir in [train_dir, test_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n\n# Split the data into train and test sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(\n    images_copy, labels_copy, test_size=0.2, stratify=labels_copy, random_state=42\n)\n\ndef save_images(images, labels, split_dir):\n    for idx, (img, label) in enumerate(zip(images, labels)):\n        class_name = class_names[label]\n        img_path = os.path.join(split_dir, class_name, f\"image_{idx}.png\")\n        # Scale image to [0, 255] and convert to uint8 for saving\n        img_scaled = (img - img.min()) / (img.max() - img.min())\n        img_uint8 = (img_scaled * 255).astype(np.uint8)\n        if len(img.shape) == 2:  # If grayscale, add channel dimension\n            img_uint8 = img_uint8[..., np.newaxis]\n        cv2.imwrite(img_path, img_uint8)\n\nsave_images(X_train, y_train, train_dir)\nsave_images(X_test, y_test, test_dir)\n\nshutil.make_archive(base_dir, 'zip', base_dir)\nshutil.rmtree(base_dir)\n\nprint(f\"\\nDataset saved as {zip_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T22:32:08.588946Z","iopub.execute_input":"2025-04-15T22:32:08.589883Z","iopub.status.idle":"2025-04-15T22:32:25.437445Z","shell.execute_reply.started":"2025-04-15T22:32:08.589849Z","shell.execute_reply":"2025-04-15T22:32:25.436530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}