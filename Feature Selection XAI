{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11426837,"sourceType":"datasetVersion","datasetId":7156670},{"sourceId":11427013,"sourceType":"datasetVersion","datasetId":7156791},{"sourceId":11445680,"sourceType":"datasetVersion","datasetId":7170518}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport cv2\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport shutil\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:59:47.990094Z","iopub.execute_input":"2025-04-17T08:59:47.990444Z","iopub.status.idle":"2025-04-17T08:59:47.996458Z","shell.execute_reply.started":"2025-04-17T08:59:47.990418Z","shell.execute_reply":"2025-04-17T08:59:47.995381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:59:48.679704Z","iopub.execute_input":"2025-04-17T08:59:48.679990Z","iopub.status.idle":"2025-04-17T08:59:54.834902Z","shell.execute_reply.started":"2025-04-17T08:59:48.679969Z","shell.execute_reply":"2025-04-17T08:59:54.833968Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = '/kaggle/input/preprocessed-dataset2'\n\ncategories = ['covid19', 'normal', 'pneumonia']\nimages = []\nlabels = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:59:54.836371Z","iopub.execute_input":"2025-04-17T08:59:54.836647Z","iopub.status.idle":"2025-04-17T08:59:54.842681Z","shell.execute_reply.started":"2025-04-17T08:59:54.836618Z","shell.execute_reply":"2025-04-17T08:59:54.841653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to load images from a directory\ndef load_images_from_folder(folder, label):\n    for filename in os.listdir(folder):\n        if filename.endswith('.jpg') or filename.endswith('.png') :  # Only process .jpg files\n            img_path = os.path.join(folder, filename)\n            try:\n                img = cv2.imread(img_path)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img = cv2.resize(img, (224, 224))\n                images.append(img)\n                labels.append(label)\n            except Exception as e:\n                print(f\"Error loading image {img_path}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:59:54.843703Z","iopub.execute_input":"2025-04-17T08:59:54.844190Z","iopub.status.idle":"2025-04-17T08:59:54.856690Z","shell.execute_reply.started":"2025-04-17T08:59:54.844137Z","shell.execute_reply":"2025-04-17T08:59:54.855825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = os.path.join(base_path, 'train')\nfor category in categories:\n    category_path = os.path.join(train_path, category)\n    print(f\"Loading training data from {category_path}...\")\n    load_images_from_folder(category_path, category)\n    \ntest_path = os.path.join(base_path, 'test')\ntest_images = []\ntest_labels = []\nfor category in categories:\n    category_path = os.path.join(test_path, category)\n    print(f\"Loading test data from {category_path}...\")\n    load_images_from_folder(category_path, category)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:59:54.859025Z","iopub.execute_input":"2025-04-17T08:59:54.859328Z","iopub.status.idle":"2025-04-17T09:00:03.618291Z","shell.execute_reply.started":"2025-04-17T08:59:54.859306Z","shell.execute_reply":"2025-04-17T09:00:03.617305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = np.array(images)\nlabels = np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:00:03.619309Z","iopub.execute_input":"2025-04-17T09:00:03.619680Z","iopub.status.idle":"2025-04-17T09:00:03.676962Z","shell.execute_reply.started":"2025-04-17T09:00:03.619646Z","shell.execute_reply":"2025-04-17T09:00:03.676113Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Remove Annotations","metadata":{}},{"cell_type":"code","source":"def remove_annotations(img, threshold=0.9):\n    img_uint8 = (img * 255).astype(np.uint8)\n    \n    img_gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n    \n    _, thresh = cv2.threshold(img_gray, int(threshold * 255), 255, cv2.THRESH_BINARY)\n    \n    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    mask = np.zeros_like(img_gray)\n    cv2.drawContours(mask, contours, -1, 255, thickness=cv2.FILLED)\n    \n    kernel = np.ones((3, 3), np.uint8)\n    mask = cv2.dilate(mask, kernel, iterations=2)\n    \n    cleaned_img = cv2.inpaint(img_uint8, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n    \n    cleaned_img = cleaned_img.astype(np.float32) / 255.0\n    return cleaned_img\n\n\ncleaned_images = []\nfor i, img in enumerate(tqdm(images, desc=\"Removing annotations\")):\n    cleaned_img = remove_annotations(img)\n    cleaned_images.append(cleaned_img)\n\nimages = cleaned_images\n\nprint(f\"Loaded and processed {len(images)} X-ray images.\")\nprint(f\"Label distribution:\\n{pd.Series(labels).value_counts()}\")\n\nn_cols = 5\nn_rows = 1\nfig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2.5))\naxes = axes.flatten()\n\nfor i in range(min(n_cols, len(images))):\n    axes[i].imshow(images[i])  \n    axes[i].set_title(labels[i], fontsize=8, pad=2)\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Annotations removed from {len(images)} X-ray images.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:00:03.677999Z","iopub.execute_input":"2025-04-17T09:00:03.678336Z","iopub.status.idle":"2025-04-17T09:00:18.312638Z","shell.execute_reply.started":"2025-04-17T09:00:03.678307Z","shell.execute_reply":"2025-04-17T09:00:18.311552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_images = len(images)\n\nstart_idx = 5\nremaining_images = images[start_idx:]\nremaining_names = labels[start_idx:]\n\nif not remaining_images:\n    print(\"No remaining images to plot. All images were plotted previously.\")\nelse:\n    n_remaining = len(remaining_images)\n    n_cols = 10\n    n_rows = int(np.ceil(n_remaining / n_cols))\n\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 2, n_rows * 2.5))\n    axes = axes.flatten() \n\n    for i in range(n_cols * n_rows):\n        if i < n_remaining:\n            axes[i].imshow(remaining_images[i], cmap='gray')\n            axes[i].set_title(remaining_names[i], fontsize=8, pad=2)\n            axes[i].axis('off')\n        else:\n            axes[i].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n    print(f\"Plotted {n_remaining} remaining cleaned X-ray images.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:00:18.313679Z","iopub.execute_input":"2025-04-17T09:00:18.313953Z","iopub.status.idle":"2025-04-17T09:02:20.801591Z","shell.execute_reply.started":"2025-04-17T09:00:18.313931Z","shell.execute_reply":"2025-04-17T09:02:20.800201Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Remove Very Bright or very dark images","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nDark_images = []\nLight_images = []\nfiltered_images = []\nfiltered_labels = []\n\nfor i, img in enumerate(images):\n    if img.dtype != np.uint8:\n        img = np.clip(img * 255, 0, 255).astype(np.uint8)\n    img_array = np.array(img)\n    mean_intensity = img_array.mean()\n\n    if mean_intensity < 60:\n        print(\"Image with index\", i, \"is too dark\")\n        Dark_images.append(img)\n    elif mean_intensity > 200:\n        print(\"Image with index\", i, \"is too light\")\n        Light_images.append(img)\n    else:\n        filtered_images.append(img)\n        filtered_labels.append(labels[i])\n\nprint(f\"There are {len(Dark_images)} images that are too dark, and {len(Light_images)} images that are too light.\")\nprint(f\"{len(filtered_images)} images passed the brightness filter.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:02:20.802882Z","iopub.execute_input":"2025-04-17T09:02:20.803246Z","iopub.status.idle":"2025-04-17T09:02:21.818978Z","shell.execute_reply.started":"2025-04-17T09:02:20.803203Z","shell.execute_reply":"2025-04-17T09:02:21.817977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save Dataset","metadata":{}},{"cell_type":"code","source":"filtered_images = np.array(filtered_images)\nfiltered_labels = np.array(filtered_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:02:21.820125Z","iopub.execute_input":"2025-04-17T09:02:21.820429Z","iopub.status.idle":"2025-04-17T09:02:21.876324Z","shell.execute_reply.started":"2025-04-17T09:02:21.820392Z","shell.execute_reply":"2025-04-17T09:02:21.875350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir = \"/kaggle/working/dataset\"\ntrain_dir = os.path.join(base_dir, \"train\")\ntest_dir = os.path.join(base_dir, \"test\")\nclass_names = ['covid19', 'normal', 'pneumonia']\nzip_file = \"dataset.zip\"\n\nfor split_dir in [train_dir, test_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n\n# Split the data into train and test sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(\n    filtered_images, filtered_labels, test_size=0.2, stratify=filtered_labels, random_state=42\n)\n\ndef save_images(images, labels, split_dir):\n    for idx, (img, label) in enumerate(zip(images, labels)):\n        class_name = label  \n        img_path = os.path.join(split_dir, class_name, f\"image_{idx}.png\")\n        img_scaled = (img - img.min()) / (img.max() - img.min())\n        img_uint8 = (img_scaled * 255).astype(np.uint8)\n        if len(img.shape) == 2:\n            img_uint8 = img_uint8[..., np.newaxis]\n        cv2.imwrite(img_path, img_uint8)\n\n\nsave_images(X_train, y_train, train_dir)\nsave_images(X_test, y_test, test_dir)\n\nshutil.make_archive(base_dir, 'zip', base_dir)\nshutil.rmtree(base_dir)\n\nprint(f\"\\nDataset saved as {zip_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T09:02:21.878381Z","iopub.execute_input":"2025-04-17T09:02:21.878633Z","iopub.status.idle":"2025-04-17T09:02:34.818859Z","shell.execute_reply.started":"2025-04-17T09:02:21.878615Z","shell.execute_reply":"2025-04-17T09:02:34.817967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}